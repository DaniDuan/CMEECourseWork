# Manual calculation of R square and AIC values given the model was logged before fitting
res = datai$trait_value - exp(Schoolfield(tran_kT = datai$tran_kT, summ$coefficients[1],
summ$coefficients[2], summ$coefficients[3], summ$coefficients[4])) # Residual
RSS_i = sum(res^2) # Residual sum of squares
TSS_i = sum((datai$trait_value - mean(datai$trait_value))^2) # Total sum of squares
Rsq_i = 1 - (RSS_i/TSS_i) # R squared
n = nrow(datai) # sample size
p_i = length(coef(School_model)) # Number of parameters
AIC_i = n+2+n*log((2*pi)/n)+n*log(RSS_i) + 2*p_i
BIC_i = n+2+n*log((2*pi)/n)+n*log(RSS_i) + p_i* log(n)
dataframe = data.frame(
ID = i,
lnB0_start = lnB0_start, Th_start = Th_start,
Ea_start = Ea_start, Eh_start = Eh_start,
lnB0 = summ$coefficients[1], Th = summ$coefficients[2],
Ea = summ$coefficients[3], Eh = summ$coefficients[4],
r2 = Rsq_i, AIC = AIC_i, BIC = BIC_i
)
School_fit = rbind(School_fit, dataframe)
}
}
}
print(i) # The progress bar~
View(School_fit)
## Fitting schoolfield with mean start values calculated using Arrhenius
School_fit = data.frame()
for(i in Arrhenius$ID){
Adatai = subset(Arrhenius, Arrhenius$ID == i) # Data subset for iteration(start values)
datai = subset(sch_cData, ID ==i) # Data subset for iteration
lnB0_get = Adatai$lnA0
Th_get = Adatai$Th
Ea_get = Adatai$Ea
Eh_get = Adatai$Eh
# Start range
set.seed(1234) # Saving random number generation pattern
# Get reasonable normal distribution range for different power of everything
lnB0_range = rnorm(100,mean = lnB0_get, sd = 5)
Th_range = rnorm(100, mean = Th_get, sd = 100)
Ea_range = rnorm(100, mean = Ea_get, sd = 10)
Eh_range = rnorm(100, mean = Eh_get, sd = abs(Eh_get))
for(n in 1:100){
lnB0_start = sample(lnB0_range,1); Th_start = sample(Th_range,1)
Ea_start = sample(Ea_range,1); Eh_start = sample(Eh_range,1)
School_model = try(nlsLM(lnB~Schoolfield(tran_kT = tran_kT, lnB0, Th, Ea, Eh),subset(sch_cData, ID ==i),
list(lnB0 = lnB0_start, Th = Th_start, Ea= Ea_start, Eh = Eh_start),
upper = c(5, 375, 10, 10),
lower = c(-5, 200, 0, 0),
control = list(maxiter = 500)), silent = T)
if(class(School_model) != "try-error"){
if(School_model$convInfo[2]<500){
summ = summary(School_model)
# Manual calculation of R square and AIC values given the model was logged before fitting
res = datai$trait_value - exp(Schoolfield(tran_kT = datai$tran_kT, summ$coefficients[1],
summ$coefficients[2], summ$coefficients[3], summ$coefficients[4])) # Residual
RSS_i = sum(res^2) # Residual sum of squares
TSS_i = sum((datai$trait_value - mean(datai$trait_value))^2) # Total sum of squares
Rsq_i = 1 - (RSS_i/TSS_i) # R squared
n = nrow(datai) # sample size
p_i = length(coef(School_model)) # Number of parameters
AIC_i = n+2+n*log((2*pi)/n)+n*log(RSS_i) + 2*p_i
BIC_i = n+2+n*log((2*pi)/n)+n*log(RSS_i) + p_i* log(n)
dataframe = data.frame(
ID = i,
lnB0_start = lnB0_start, Th_start = Th_start,
Ea_start = Ea_start, Eh_start = Eh_start,
lnB0 = summ$coefficients[1], Th = summ$coefficients[2],
Ea = summ$coefficients[3], Eh = summ$coefficients[4],
r2 = Rsq_i, AIC = AIC_i, BIC = BIC_i
)
School_fit = rbind(School_fit, dataframe)
}
}
}
print(i) # The progress bar~
}
View(School_fit)
## Fitting schoolfield with mean start values calculated using Arrhenius
School_fit = data.frame()
for(i in Arrhenius$ID){
Adatai = subset(Arrhenius, Arrhenius$ID == i) # Data subset for iteration(start values)
datai = subset(sch_cData, ID ==i) # Data subset for iteration
lnB0_get = Adatai$lnA0
Th_get = Adatai$Th
Ea_get = Adatai$Ea
Eh_get = Adatai$Eh
# Start range
set.seed(1234) # Saving random number generation pattern
# Get reasonable normal distribution range for different power of everything
lnB0_range = rnorm(100,mean = lnB0_get, sd = 5)
Th_range = rnorm(100, mean = Th_get, sd = 100)
Ea_range = rnorm(100, mean = Ea_get, sd = 10)
Eh_range = rnorm(100, mean = Eh_get, sd = abs(Eh_get))
for(n in 1:100){
lnB0_start = sample(lnB0_range,1); Th_start = sample(Th_range,1)
Ea_start = sample(Ea_range,1); Eh_start = sample(Eh_range,1)
School_model = try(nlsLM(lnB~Schoolfield(tran_kT = tran_kT, lnB0, Th, Ea, Eh),subset(sch_cData, ID ==i),
list(lnB0 = lnB0_start, Th = Th_start, Ea= Ea_start, Eh = Eh_start),
upper = c(Inf, 375, 10, 10),
lower = c(-Inf, 200, 0, 0),
control = list(maxiter = 500)), silent = T)
if(class(School_model) != "try-error"){
if(School_model$convInfo[2]<500){
summ = summary(School_model)
# Manual calculation of R square and AIC values given the model was logged before fitting
res = datai$trait_value - exp(Schoolfield(tran_kT = datai$tran_kT, summ$coefficients[1],
summ$coefficients[2], summ$coefficients[3], summ$coefficients[4])) # Residual
RSS_i = sum(res^2) # Residual sum of squares
TSS_i = sum((datai$trait_value - mean(datai$trait_value))^2) # Total sum of squares
Rsq_i = 1 - (RSS_i/TSS_i) # R squared
n = nrow(datai) # sample size
p_i = length(coef(School_model)) # Number of parameters
AIC_i = n+2+n*log((2*pi)/n)+n*log(RSS_i) + 2*p_i
BIC_i = n+2+n*log((2*pi)/n)+n*log(RSS_i) + p_i* log(n)
dataframe = data.frame(
ID = i,
lnB0_start = lnB0_start, Th_start = Th_start,
Ea_start = Ea_start, Eh_start = Eh_start,
lnB0 = summ$coefficients[1], Th = summ$coefficients[2],
Ea = summ$coefficients[3], Eh = summ$coefficients[4],
r2 = Rsq_i, AIC = AIC_i, BIC = BIC_i
)
School_fit = rbind(School_fit, dataframe)
}
}
}
print(i) # The progress bar~
}
# Selecting the best AIC fitting for each sample ID
School_fit_AIC = data.frame()
for(i in unique(School_fit$ID)){
x = School_fit[School_fit$ID == i,][which.min(School_fit$AIC[School_fit$ID == i]),]
School_fit_AIC = rbind(School_fit_AIC,x)
}
View(School_fit_AIC)
min(Briere_AIC$B0)
max(Briere_AIC$B0)
max(cData$trait_value)
cData$ID[cData$trait_value == max(cData$trait_value)]
Briere_AIC$B0[Briere_AIC$ID == 443]
###########Plotting Everything################
pdf("../results/2+3+b+s_plots_AIC.pdf")
for(i in unique(cData$ID)){
datai = subset(cData, cData$ID == i) # Data subset for iteration
t_max = max(datai$temp)
t_min = min(datai$temp)
t_points = seq(t_min, t_max, 0.1)
plot(datai$temp, datai$trait_value, xlab = "Temperature(celsius)", ylab = c(unique(datai$trait_name), unique(datai$trait_unit)), ylim = c(0.95*min(datai$trait_value),1.1*max(datai$trait_value)))
plm2 = try(lm(trait_value ~poly(temp,2), data = datai), silent = T)
if(class(plm2) != "try-error"){
plm2_pre = predict(plm2, newdata = list(temp = t_points))
lines(t_points, plm2_pre, col = 2)
}
plm3 = try(lm(trait_value ~poly(temp,3), data = datai), silent = T)
if(class(plm3) != "try-error"){
plm3_pre = predict(plm3, newdata = list(temp = t_points))
lines(t_points, plm3_pre, col = 3)
}
Bdatai = subset(Briere_AIC, Briere_AIC$ID == i)
nlm_pre = Briere_AIC$B0[Briere_AIC$ID == i]*t_points*(t_points-Briere_AIC$T0[Briere_AIC$ID == i])*(Briere_AIC$Tm[Briere_AIC$ID == i]-t_points)^0.5
try(lines(t_points, nlm_pre, col = 4), silent = T)
datas = subset(sch_cData, sch_cData$ID == i) # Data subset for iteration(Schoolfield)
dataA = subset(School_fit_AIC, School_fit_AIC$ID ==i) # Data subset for starting values
tran_kT = -1/(k*(t_points+273.15))
nlm_pre_school = exp(School_fit_AIC$lnB0[School_fit_AIC$ID == i])*exp((tran_kT+(1/283.15*k))*School_fit_AIC$Ea[School_fit_AIC$ID == i])/(1+exp((1/(School_fit_AIC$Th[School_fit_AIC$ID == i]*k)+tran_kT)*School_fit_AIC$Eh[School_fit_AIC$ID == i]))
try(lines(t_points, nlm_pre_school, col = 7), silent = T)
legend("topleft", legend = c("quadratic","cubic", "Briere", "Schoolfield"), lwd = 2, col = c(2:4, 7))
text(max(datai$temp), 1.1*max(datai$trait_value), i, pos = c(1,2))
print(i) # The progress bar~~
}
graphics.off()
## Fitting the Briere model
Briere_model_fitting = as.data.frame(matrix(NA, nr=90300, nc=12)) # Creating an empty data frame for filling in
system.time(
for(i in unique(cData$ID)){
datai = subset(cData, cData$ID==i) #Data subset for iteration
T0_start = min(datai$temp)
Tm_start = max(datai$temp)
# Calculate a mean value for B0 start distribution
B0_est = datai$trait_value/(datai$temp*(datai$temp - T0_start)*(Tm_start - datai$temp)^0.5)
B0_est = B0_est[!is.nan(B0_est)]
B0_start_est = mean(B0_est[B0_est != Inf])
set.seed(1234) #Saving random number generation pattern
# Get a reasonable normal distribution range for different power of B0 start
B0_start_range = rnorm(100, mean = B0_start_est, sd = abs(B0_start_est))
# Start to sample and fit through B0 starting value range
for(n in 1:100){
non_linear = try(nlsLM(trait_value~Briere(Temp = temp, T0, Tm, B0), datai,
list(T0 =T0_start, Tm = Tm_start, B0 = B0_start_range[n]),
upper = c(40, 100, 2*B0_start_est),
lower = c(-80, 0, 0),
control = list(maxiter = 500)), silent = T) # Fitting nlm Briere model
if(class(non_linear) != "try-error" && non_linear$convInfo[2]<500){ #if no error detected and didnt exceed maxiter
summ = summary(non_linear)
Briere_model_fitting[(i-1)*100+n,] = c(as.numeric(i), unique(datai$consumer),
unique(datai$trait_name),
B0_start_range[n],
summ$coefficients[1], summ$coefficients[2],summ$coefficients[3],
AIC(non_linear), BIC(non_linear),
unique(datai$habitat), unique(datai$location), unique(datai$stage))
}
}
print(i) # The progress bar~~
})
colnames(Briere_model_fitting) = c('ID', 'consumer', 'trait_name', 'B0start', 'T0', 'Tm', 'B0', 'AIC', 'BIC', 'habitat', 'location', 'stage')
#Select on AIC
Briere_AIC = data.frame()
for(i in unique(Briere_model_fitting$ID)){
x = Briere_model_fitting[Briere_model_fitting$ID == i,][which.min(Briere_model_fitting$AIC[Briere_model_fitting$ID == i]),]
Briere_AIC = rbind(Briere_AIC,x)
}
Briere_AIC$ID = as.numeric(Briere_AIC$ID)
Briere_AIC$T0 = as.numeric(Briere_AIC$T0)
Briere_AIC$Tm = as.numeric(Briere_AIC$Tm)
Briere_AIC$B0 = as.numeric(Briere_AIC$B0)
Briere_AIC$AIC = as.numeric(Briere_AIC$AIC)
View(Briere_AIC)
Briere_model_fitting$ID = as.numeric(Briere_model_fitting$ID)
Briere_model_fitting$T0 = as.numeric(Briere_model_fitting$T0)
Briere_model_fitting$Tm = as.numeric(Briere_model_fitting$Tm)
Briere_model_fitting$B0 = as.numeric(Briere_model_fitting$B0)
Briere_model_fitting$AIC = as.numeric(Briere_model_fitting$AIC)
#Select on AIC
Briere_AIC = data.frame()
for(i in unique(Briere_model_fitting$ID)){
x = Briere_model_fitting[Briere_model_fitting$ID == i,][which.min(Briere_model_fitting$AIC[Briere_model_fitting$ID == i]),]
Briere_AIC = rbind(Briere_AIC,x)
}
# Selecting the best AIC fitting for each sample ID
School_fit_AIC = data.frame()
for(i in unique(School_fit$ID)){
x = School_fit[School_fit$ID == i,][which.min(School_fit$AIC[School_fit$ID == i]),]
School_fit_AIC = rbind(School_fit_AIC,x)
}
###########Plotting Everything################
pdf("../results/2+3+b+s_plots_AIC.pdf")
for(i in unique(cData$ID)){
datai = subset(cData, cData$ID == i) # Data subset for iteration
t_max = max(datai$temp)
t_min = min(datai$temp)
t_points = seq(t_min, t_max, 0.1)
plot(datai$temp, datai$trait_value, xlab = "Temperature(celsius)", ylab = c(unique(datai$trait_name), unique(datai$trait_unit)), ylim = c(0.95*min(datai$trait_value),1.1*max(datai$trait_value)))
plm2 = try(lm(trait_value ~poly(temp,2), data = datai), silent = T)
if(class(plm2) != "try-error"){
plm2_pre = predict(plm2, newdata = list(temp = t_points))
lines(t_points, plm2_pre, col = 2)
}
plm3 = try(lm(trait_value ~poly(temp,3), data = datai), silent = T)
if(class(plm3) != "try-error"){
plm3_pre = predict(plm3, newdata = list(temp = t_points))
lines(t_points, plm3_pre, col = 3)
}
Bdatai = subset(Briere_AIC, Briere_AIC$ID == i)
nlm_pre = Briere_AIC$B0[Briere_AIC$ID == i]*t_points*(t_points-Briere_AIC$T0[Briere_AIC$ID == i])*(Briere_AIC$Tm[Briere_AIC$ID == i]-t_points)^0.5
try(lines(t_points, nlm_pre, col = 4), silent = T)
datas = subset(sch_cData, sch_cData$ID == i) # Data subset for iteration(Schoolfield)
dataA = subset(School_fit_AIC, School_fit_AIC$ID ==i) # Data subset for starting values
tran_kT = -1/(k*(t_points+273.15))
nlm_pre_school = exp(School_fit_AIC$lnB0[School_fit_AIC$ID == i])*exp((tran_kT+(1/283.15*k))*School_fit_AIC$Ea[School_fit_AIC$ID == i])/(1+exp((1/(School_fit_AIC$Th[School_fit_AIC$ID == i]*k)+tran_kT)*School_fit_AIC$Eh[School_fit_AIC$ID == i]))
try(lines(t_points, nlm_pre_school, col = 7), silent = T)
legend("topleft", legend = c("quadratic","cubic", "Briere", "Schoolfield"), lwd = 2, col = c(2:4, 7))
text(max(datai$temp), 1.1*max(datai$trait_value), i, pos = c(1,2))
print(i) # The progress bar~~
}
graphics.off()
min(School_fit_AIC$Th)
## Fitting schoolfield with mean start values calculated using Arrhenius
School_fit = data.frame()
for(i in Arrhenius$ID){
Adatai = subset(Arrhenius, Arrhenius$ID == i) # Data subset for iteration(start values)
datai = subset(sch_cData, ID ==i) # Data subset for iteration
lnB0_get = Adatai$lnA0
Th_get = Adatai$Th
Ea_get = Adatai$Ea
Eh_get = Adatai$Eh
# Start range
set.seed(1234) # Saving random number generation pattern
# Get reasonable normal distribution range for different power of everything
lnB0_range = rnorm(100,mean = lnB0_get, sd = 5)
Th_range = rnorm(100, mean = Th_get, sd = 100)
Ea_range = rnorm(100, mean = Ea_get, sd = 10)
Eh_range = rnorm(100, mean = Eh_get, sd = abs(Eh_get))
for(n in 1:100){
lnB0_start = sample(lnB0_range,1); Th_start = sample(Th_range,1)
Ea_start = sample(Ea_range,1); Eh_start = sample(Eh_range,1)
School_model = try(nlsLM(lnB~Schoolfield(tran_kT = tran_kT, lnB0, Th, Ea, Eh),subset(sch_cData, ID ==i),
list(lnB0 = lnB0_start, Th = Th_start, Ea= Ea_start, Eh = Eh_start),
upper = c(Inf, 375, 5, 20),
lower = c(-Inf, 270, 0, 0),
control = list(maxiter = 500)), silent = T)
if(class(School_model) != "try-error"){
if(School_model$convInfo[2]<500){
summ = summary(School_model)
# Manual calculation of R square and AIC values given the model was logged before fitting
res = datai$trait_value - exp(Schoolfield(tran_kT = datai$tran_kT, summ$coefficients[1],
summ$coefficients[2], summ$coefficients[3], summ$coefficients[4])) # Residual
RSS_i = sum(res^2) # Residual sum of squares
TSS_i = sum((datai$trait_value - mean(datai$trait_value))^2) # Total sum of squares
Rsq_i = 1 - (RSS_i/TSS_i) # R squared
n = nrow(datai) # sample size
p_i = length(coef(School_model)) # Number of parameters
AIC_i = n+2+n*log((2*pi)/n)+n*log(RSS_i) + 2*p_i
BIC_i = n+2+n*log((2*pi)/n)+n*log(RSS_i) + p_i* log(n)
dataframe = data.frame(
ID = i,
lnB0_start = lnB0_start, Th_start = Th_start,
Ea_start = Ea_start, Eh_start = Eh_start,
lnB0 = summ$coefficients[1], Th = summ$coefficients[2],
Ea = summ$coefficients[3], Eh = summ$coefficients[4],
r2 = Rsq_i, AIC = AIC_i, BIC = BIC_i
)
School_fit = rbind(School_fit, dataframe)
}
}
}
print(i) # The progress bar~
}
# #Output csv
# write.csv(School_fit, "../results/School_fit.csv", row.names = F)
# #Import csv
School_fit = read.csv("../results/School_fit.csv", header =T)
## Fitting schoolfield with mean start values calculated using Arrhenius
School_fit = data.frame()
for(i in Arrhenius$ID){
Adatai = subset(Arrhenius, Arrhenius$ID == i) # Data subset for iteration(start values)
datai = subset(sch_cData, ID ==i) # Data subset for iteration
lnB0_get = Adatai$lnA0
Th_get = Adatai$Th
Ea_get = Adatai$Ea
Eh_get = Adatai$Eh
# Start range
set.seed(1234) # Saving random number generation pattern
# Get reasonable normal distribution range for different power of everything
lnB0_range = rnorm(100,mean = lnB0_get, sd = 5)
Th_range = rnorm(100, mean = Th_get, sd = 100)
Ea_range = rnorm(100, mean = Ea_get, sd = 10)
Eh_range = rnorm(100, mean = Eh_get, sd = abs(Eh_get))
for(n in 1:100){
lnB0_start = sample(lnB0_range,1); Th_start = sample(Th_range,1)
Ea_start = sample(Ea_range,1); Eh_start = sample(Eh_range,1)
School_model = try(nlsLM(lnB~Schoolfield(tran_kT = tran_kT, lnB0, Th, Ea, Eh),subset(sch_cData, ID ==i),
list(lnB0 = lnB0_start, Th = Th_start, Ea= Ea_start, Eh = Eh_start),
upper = c(Inf, 375, 5, 20),
lower = c(-Inf, 270, 0, 0),
control = list(maxiter = 500)), silent = T)
if(class(School_model) != "try-error"){
if(School_model$convInfo[2]<500){
summ = summary(School_model)
# Manual calculation of R square and AIC values given the model was logged before fitting
res = datai$trait_value - exp(Schoolfield(tran_kT = datai$tran_kT, summ$coefficients[1],
summ$coefficients[2], summ$coefficients[3], summ$coefficients[4])) # Residual
RSS_i = sum(res^2) # Residual sum of squares
TSS_i = sum((datai$trait_value - mean(datai$trait_value))^2) # Total sum of squares
Rsq_i = 1 - (RSS_i/TSS_i) # R squared
n = nrow(datai) # sample size
p_i = length(coef(School_model)) # Number of parameters
AIC_i = n+2+n*log((2*pi)/n)+n*log(RSS_i) + 2*p_i
BIC_i = n+2+n*log((2*pi)/n)+n*log(RSS_i) + p_i* log(n)
dataframe = data.frame(
ID = i,
lnB0_start = lnB0_start, Th_start = Th_start,
Ea_start = Ea_start, Eh_start = Eh_start,
lnB0 = summ$coefficients[1], Th = summ$coefficients[2],
Ea = summ$coefficients[3], Eh = summ$coefficients[4],
r2 = Rsq_i, AIC = AIC_i, BIC = BIC_i
)
School_fit = rbind(School_fit, dataframe)
}
}
}
print(i) # The progress bar~
}
# Selecting the best AIC fitting for each sample ID
School_fit_AIC = data.frame()
for(i in unique(School_fit$ID)){
x = School_fit[School_fit$ID == i,][which.min(School_fit$AIC[School_fit$ID == i]),]
School_fit_AIC = rbind(School_fit_AIC,x)
}
View(School_fit_AIC)
###########Plotting Everything################
pdf("../results/2+3+b+s_plots_AIC.pdf")
for(i in unique(cData$ID)){
datai = subset(cData, cData$ID == i) # Data subset for iteration
t_max = max(datai$temp)
t_min = min(datai$temp)
t_points = seq(t_min, t_max, 0.1)
plot(datai$temp, datai$trait_value, xlab = "Temperature(celsius)", ylab = c(unique(datai$trait_name), unique(datai$trait_unit)), ylim = c(0.95*min(datai$trait_value),1.1*max(datai$trait_value)))
plm2 = try(lm(trait_value ~poly(temp,2), data = datai), silent = T)
if(class(plm2) != "try-error"){
plm2_pre = predict(plm2, newdata = list(temp = t_points))
lines(t_points, plm2_pre, col = 2)
}
plm3 = try(lm(trait_value ~poly(temp,3), data = datai), silent = T)
if(class(plm3) != "try-error"){
plm3_pre = predict(plm3, newdata = list(temp = t_points))
lines(t_points, plm3_pre, col = 3)
}
Bdatai = subset(Briere_AIC, Briere_AIC$ID == i)
nlm_pre = Briere_AIC$B0[Briere_AIC$ID == i]*t_points*(t_points-Briere_AIC$T0[Briere_AIC$ID == i])*(Briere_AIC$Tm[Briere_AIC$ID == i]-t_points)^0.5
try(lines(t_points, nlm_pre, col = 4), silent = T)
datas = subset(sch_cData, sch_cData$ID == i) # Data subset for iteration(Schoolfield)
dataA = subset(School_fit_AIC, School_fit_AIC$ID ==i) # Data subset for starting values
tran_kT = -1/(k*(t_points+273.15))
nlm_pre_school = exp(School_fit_AIC$lnB0[School_fit_AIC$ID == i])*exp((tran_kT+(1/283.15*k))*School_fit_AIC$Ea[School_fit_AIC$ID == i])/(1+exp((1/(School_fit_AIC$Th[School_fit_AIC$ID == i]*k)+tran_kT)*School_fit_AIC$Eh[School_fit_AIC$ID == i]))
try(lines(t_points, nlm_pre_school, col = 7), silent = T)
legend("topleft", legend = c("quadratic","cubic", "Briere", "Schoolfield"), lwd = 2, col = c(2:4, 7))
text(max(datai$temp), 1.1*max(datai$trait_value), i, pos = c(1,2))
print(i) # The progress bar~~
}
graphics.off()
# #Output csv
write.csv(School_fit, "../results/School_fit.csv", row.names = F)
# #Output csv
write.csv(Arrhenius, "../results/Arrhenius.csv", row.names = F)
# #Output csv
write.csv(Briere_model_fitting, "../results/Briere_model_fitting_FullResult.csv", row.names = F)
##############Comparing models based on AIC values############
#Comparing and selecting the lowest AIC values as the best fit
Compare_AIC = as.data.frame(matrix(NA, nr=903, nc=5))
for(i in 1:903){
Compare_AIC[i,1] = i
if(any(lm2_model_fitting$ID == i,na.rm = T)) Compare_AIC[i, 2] = lm2_model_fitting$AIC[lm2_model_fitting$ID == i]
if(any(lm3_model_fitting$ID == i,na.rm = T)) Compare_AIC[i, 3] = lm3_model_fitting$AIC[lm3_model_fitting$ID == i]
if(any(Briere_AIC$ID == i, na.rm = T)) Compare_AIC[i, 4] = Briere_AIC$AIC[Briere_AIC$ID == i]
if(any(School_fit_AIC$ID == i, na.rm = T)) Compare_AIC[i, 5] = School_fit_AIC$AIC[School_fit_AIC$ID == i]
}
colnames(Compare_AIC) = c("ID", "quadratic", "cubic", "Briere", "Schoolfield")
Compare_AIC = Compare_AIC[-which(is.na(Compare_AIC$quadratic)),]
##############Comparing models based on AIC values############
#Comparing and selecting the lowest AIC values as the best fit
Compare_AIC = as.data.frame(matrix(NA, nr=903, nc=5))
for(i in 1:903){
Compare_AIC[i,1] = i
if(any(lm2_model_fitting$ID == i,na.rm = T)) Compare_AIC[i, 2] = lm2_model_fitting$AIC[lm2_model_fitting$ID == i]
if(any(lm3_model_fitting$ID == i,na.rm = T)) Compare_AIC[i, 3] = lm3_model_fitting$AIC[lm3_model_fitting$ID == i]
if(any(Briere_AIC$ID == i, na.rm = T)) Compare_AIC[i, 4] = Briere_AIC$AIC[Briere_AIC$ID == i]
if(any(School_fit_AIC$ID == i, na.rm = T)) Compare_AIC[i, 5] = School_fit_AIC$AIC[School_fit_AIC$ID == i]
}
colnames(Compare_AIC) = c("ID", "quadratic", "cubic", "Briere", "Schoolfield")
Compare_AIC = Compare_AIC[-which(is.na(Compare_AIC$quadratic)),]
Best_fit = colnames(Compare_AIC[,2:5])[apply(Compare_AIC[,2:5], 1, function(x) which(x == min(x, na.rm = T)))]
Best_fit_nlm = colnames(Compare_AIC[,4:5])[apply(Compare_AIC[,4:5], 1, function(x) which(x == min(x, na.rm = T)))]
Compare_AIC = cbind(Compare_AIC, Best_fit,Best_fit_nlm, lm2_model_fitting[,c(2:3, 8:10)])
View(Compare_AIC)
# #Export csv
write.csv(Compare_AIC, "../results/Compare_AIC.csv", row.names = F)
# #Import csv
Compare_AIC = read.csv("../results/Compare_AIC.csv", header = T)
sum(Compare_AIC$Best_fit == "quadratic")/nrow(Compare_AIC) #percentage of this model being the best fit
sum(Compare_AIC$Best_fit == "cubic")/nrow(Compare_AIC)
sum(Compare_AIC$Best_fit == "Briere")/nrow(Compare_AIC)
sum(Compare_AIC$Best_fit == "Schoolfield")/nrow(Compare_AIC)
sum(Compare_AIC$Best_fit_nlm == "Briere")/nrow(Compare_AIC)
sum(Compare_AIC$Best_fit_nlm == "Schoolfield")/nrow(Compare_AIC)
#Subsets with trait name
unique(Compare_AIC$trait_name)
net_photosynthesis_rate = subset(Compare_AIC, Compare_AIC$trait_name == "net photosynthesis rate")
gross_photosynthesis_rate = subset(Compare_AIC, Compare_AIC$trait_name == "gross photosynthesis rate")
respiration_rate = subset(Compare_AIC, Compare_AIC$trait_name == "respiration rate")
bestfit = c(); net = c(); gross = c(); resp = c()
for(i in unique(Compare_AIC$Best_fit)){
bestfit = c(bestfit, i)
net = c(net, sum(net_photosynthesis_rate$Best_fit == i)/nrow(net_photosynthesis_rate))
gross = c(gross, sum(gross_photosynthesis_rate$Best_fit == i)/nrow(gross_photosynthesis_rate))
resp = c(resp, sum(respiration_rate$Best_fit == i)/nrow(respiration_rate))
}
subAIC_traitname = cbind(bestfit, net, gross, resp)
View(subAIC_traitname)
#Subsets with habitat
unique(Compare_AIC$habitat)
ter =  subset(Compare_AIC, Compare_AIC$habitat == "terrestrial")
mar = subset(Compare_AIC, Compare_AIC$habitat == "marine")
fre = subset(Compare_AIC, Compare_AIC$habitat == "freshwater")
fre_ter = subset(Compare_AIC, Compare_AIC$habitat == "freshwater / terrestrial")
aqu = subset(Compare_AIC, Compare_AIC$habitat == "aquatic")
bestfit = c(); terrestrial = c(); marine = c(); freshwater = c(); freshwater_terrestrial = c(); aquatic = c()
for(i in unique(Compare_AIC$Best_fit)){
bestfit = c(bestfit, i)
terrestrial = c(terrestrial, sum(ter$Best_fit == i)/nrow(ter))
marine = c(marine, sum(mar$Best_fit == i)/nrow(mar))
freshwater = c(freshwater, sum(fre$Best_fit == i)/nrow(fre))
freshwater_terrestrial = c(freshwater_terrestrial, sum(fre_ter$Best_fit == i)/nrow(fre_ter))
aquatic = c(aquatic, sum(aqu$Best_fit == i)/nrow(aqu))
}
subAIC_habitat = cbind(bestfit, terrestrial, marine, freshwater, freshwater_terrestrial, aquatic)
View(subAIC_habitat)
length(cData$ID[cData$ID == 527])
length(cData$ID[cData$ID == 3])
length(cData$ID[cData$ID == 33])
length(cData$ID[cData$ID == 73])
length(cData$ID[cData$ID == 67])
length(cData$ID[cData$ID == 379])
length(cData$ID[cData$ID == 608])
length(cData$ID[cData$ID == 605])
length(cData$ID[cData$ID == 583])
length(cData$ID[cData$ID == 607])
length(cData$ID[cData$ID == 606])
length(cData$ID[cData$ID == 849])
length(cData$ID[cData$ID == 851])
length(cData$ID[cData$ID == 607])
length(cData$ID[cData$ID == 529])
length(cData$ID[cData$ID == 584])
length(cData$ID[cData$ID == 848])
length(cData$ID[cData$ID == 202])
length(cData$ID[cData$ID == 544])
length(cData$ID[cData$ID == 538])
length(cData$ID[cData$ID == 254])
length(cData$ID[cData$ID == 31])
View(subAIC_habitat)
sum(Compare_AIC$Best_fit == "quadratic")/nrow(Compare_AIC) #percentage of this model being the best fit
sum(Compare_AIC$Best_fit == "cubic")/nrow(Compare_AIC)
sum(Compare_AIC$Best_fit == "Briere")/nrow(Compare_AIC)
sum(Compare_AIC$Best_fit == "Schoolfield")/nrow(Compare_AIC)
